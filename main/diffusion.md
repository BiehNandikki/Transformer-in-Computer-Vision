### Diffusion
- (arXiv 2022.12) Scalable Diffusion Models with Transformers, [[Paper]](https://arxiv.org/pdf/2212.09748.pdf), [[Code]](https://www.wpeebles.com/DiT)
- (arXiv 2023.03) Masked Diffusion Transformer is a Strong Image Synthesizer, [[Paper]](https://arxiv.org/pdf/2303.14389.pdf), [[Code]](https://github.com/sail-sg/MDT)
- (arXiv 2023.04) ViT-DAE: Transformer-driven Diffusion Autoencoder for Histopathology Image Analysis, [[Paper]](https://arxiv.org/pdf/2304.01053.pdf)
- (arXiv 2023.06) DFormer: Diffusion-guided Transformer for Universal Image Segmentation, [[Paper]](https://arxiv.org/pdf/2306.03437.pdf), [[Code]](https://github.com/cp3wan/DFormer)
- (arXiv 2023.08) Unaligned 2D to 3D Translation with Conditional Vector-Quantized Code Diffusion using Transformers, [[Paper]](https://arxiv.org/pdf/2308.14152.pdf)
- (arXiv 2023.09) Large-Vocabulary 3D Diffusion Model with Transformer, [[Paper]](https://arxiv.org/pdf/2309.07920.pdf), [[Project]](https://ziangcao0312.github.io/difftf_pages/)
- (arXiv 2023.09) Cartoondiff: Training-free Cartoon Image Generation with Diffusion Transformer Models, [[Paper]](https://arxiv.org/pdf/2309.08251.pdf), [[Project]](https://cartoondiff.github.io/)
- (arXiv 2023.12) DiffiT: Diffusion Vision Transformers for Image Generation, [[Paper]](https://arxiv.org/pdf/2312.02139.pdf)
- (arXiv 2023.12) DiT-Head: High-Resolution Talking Head Synthesis using Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2312.06400.pdf)
- (arXiv 2024.01) SiT: Exploring Flow and Diffusion-based Generative Models with Scalable Interpolant Transformers, [[Paper]](https://arxiv.org/pdf/2401.08740.pdf), [[Code]](https://github.com/willisma/SiT)
- (arXiv 2024.01) Scalable High-Resolution Pixel-Space Image Synthesis with Hourglass Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2401.11605.pdf), [[Code]](https://crowsonkb.github.io/hourglass-diffusion-transformers)
- (arXiv 2024.02) Cross-view Masked Diffusion Transformers for Person Image Synthesis, [[Paper]](https://arxiv.org/pdf/2402.01516.pdf)
- (arXiv 2024.02) FiT: Flexible Vision Transformer for Diffusion Model, [[Paper]](https://arxiv.org/pdf/2402.12376.pdf), [[Code]](https://github.com/whlzy/FiT)
- (arXiv 2024.03) Switch Diffusion Transformer: Synergizing Denoising Tasks with Sparse Mixture-of-Experts, [[Paper]](https://arxiv.org/pdf/2403.09176.pdf), [[Code]](https://byeongjun-park.github.io/Switch-DiT/)
- (arXiv 2024.03) SD-DiT: Unleashing the Power of Self-supervised Discrimination in Diffusion Transformer, [[Paper]](https://arxiv.org/pdf/2403.17004.pdf)
- (arXiv 2024.04) WcDT: World-centric Diffusion Transformer for Traffic Scene Generation, [[Paper]](https://arxiv.org/pdf/2404.02082.pdf)
- (arXiv 2024.04) Solving Masked Jigsaw Puzzles with Diffusion Vision Transformers, [[Paper]](https://arxiv.org/pdf/2404.07292.pdf)
- (arXiv 2024.04) Diffscaler: Enhancing the Generative Prowess of Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2404.09976.pdf)
- (arXiv 2024.04) Lazy Diffusion Transformer for Interactive Image Editing, [[Paper]](https://arxiv.org/pdf/2404.12382.pdf), [[Project]](https://lazydiffusion.github.io/)
- (arXiv 2024.05) U-DiTs: Downsample Tokens in U-Shaped Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2405.02730.pdf), [[Code]](https://github.com/YuchuanTian/U-DiT)
- (arXiv 2024.05) Inf-DiT: Upsampling Any-Resolution Image with Memory-Efficient Diffusion Transformer, [[Paper]](https://arxiv.org/pdf/2405.04312.pdf), [[Code]](https://github.com/THUDM/Inf-DiT)
- (arXiv 2024.05) Lumina-T2X: Transforming Text into Any Modality, Resolution, and Duration via Flow-based Large Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2405.05945.pdf), [[Code]](https://github.com/THUDM/Inf-DiT)
- (arXiv 2024.05) DiffTF++: 3D-aware Diffusion Transformer for Large-Vocabulary 3D Generation, [[Paper]](https://arxiv.org/pdf/2405.08055.pdf)
- (arXiv 2024.05) Hunyuan-DiT: A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding, [[Paper]](https://arxiv.org/pdf/2405.08748.pdf),[[Code]](http://github.com/Tencent/HunyuanDiT)
- (arXiv 2024.05) Direct3D: Scalable Image-to-3D Generation via 3D Latent Diffusion Transformer, [[Paper]](https://arxiv.org/pdf/2405.14832.pdf),[[Project]](https://nju-3dv.github.io/projects/Direct3D/)
- (arXiv 2024.05) PipeFusion: Displaced Patch Pipeline Parallelism for Inference of Diffusion Transformer Models, [[Paper]](https://arxiv.org/pdf/2405.14430.pdf),[[Code]](https://github.com/PipeFusion/PipeFusion)
- (arXiv 2024.05) Human4DiT: Free-view Human Video Generation with 4D Diffusion Transformer, [[Paper]](https://arxiv.org/pdf/2405.17405.pdf),[[Code]](https://human4dit.github.io/)
- (arXiv 2024.05) PTQ4DiT: Post-training Quantization for Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2405.16005.pdf)
- (arXiv 2024.05) VITON-DiT: Learning In-the-Wild Video Try-On from Human Dance Videos via Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2405.18326.pdf),[[Code]](https://zhengjun-ai.github.io/viton-dit-page/)
- (arXiv 2024.05) DiG: Scalable and Efficient Diffusion Models with Gated Linear Attention, [[Paper]](https://arxiv.org/pdf/2405.18428.pdf),[[Code]](https://github.com/hustvl/DiG)
- (arXiv 2024.06) Î”-DiT: A Training-Free Acceleration Method Tailored for Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2406.01125)
- (arXiv 2024.06) Dimba: Transformer-Mamba Diffusion Models, [[Paper]](https://arxiv.org/pdf/2406.01159),[[Code]](https://dimba-project.github.io/)
- (arXiv 2024.06) AV-DiT: Efficient Audio-Visual Diffusion Transformer for Joint Audio and Video Generation, [[Paper]](https://arxiv.org/pdf/2406.07686)
- (arXiv 2024.06) DiTFastAttn: Attention Compression for Diffusion Transformer Models, [[Paper]](https://arxiv.org/pdf/2406.08552),[[Code]](https://github.com/thu-nics/DiTFastAttn)
- (arXiv 2024.06) Lumina-Next: Making Lumina-T2X Stronger and Faster with Next-DiT, [[Paper]](https://arxiv.org/pdf/2406.18583),[[Code]](https://github.com/Alpha-VLLM/Lumina-T2X)
